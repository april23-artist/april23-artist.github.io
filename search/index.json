[{"content":"前言 步驟 取得 DockerHub 的 Personal access token DockerHub 新增 Personal access token。 設定 GitHub Repository secrets GitHub 設定 DockerHub 的使用者名稱以及 Personal access token。 設定 Repository Workflow 在 Repository 根目錄中的 .gethub\\workflows\\deploy.yaml 加入以下流程。 該專案使用 docker-compose 所以直接將整個 docker-compose 推送到 DockerHub。\nname: Build and Push Docker Images using Docker Compose on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Log in to Docker Hub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKER_USERNAME }} # DockerHub 使用者名稱 password: ${{ secrets.DOCKER_PASSWORD }} # DockerHub Personal access token - name: Install docker-compose run: | sudo apt-get update sudo apt-get install -y docker-compose - name: Build and push Docker images run: | cd src # 將工作目錄移到有 docker-compose.yml 所在的 src 資料夾 docker-compose -f docker-compose.yml build docker-compose push ","date":"2025-01-02T00:00:00Z","permalink":"https://april23-artist.github.io/p/github-actions-push-image-to-dockerhub/","title":"透過 GitHub Actions 將 Image 推送到 DockerHub"},{"content":"前言 Kubernetes Ingress 是一種用於管理外部訪問 Kubernetes 叢集中服務的方式。它提供了 HTTP 和 HTTPS 路由功能，允許外部用戶通過單一 IP 地址訪問多個服務。\n主要功能:\n路由：根據 HTTP/HTTPS 請求的 URL 路徑或主機名，將流量路由到不同的服務。 負載均衡：在多個後端服務實例之間分配流量，實現負載均衡。 SSL/TLS 終止：處理 HTTPS 請求，提供 SSL/TLS 終止功能。 虛擬主機：支持基於主機名的虛擬主機配置，允許多個域名共享同一個 IP 地址。 Ingress 需要搭配 Ingress Controller 使用，是一個負責處理 Ingress 資源的控制器。常見的 Ingress Controller 有:\nNginx Traefik Ingress 是一種抽象，nginx則是實作抽象\nIngress 用於定義如何將外部流量路由到 Kubernetes 叢集中的服務。 Nginx 實作這個抽象的工具，作為 Ingress Controller 來處理和路由流量。 步驟 檢查 kube-system 命名空間中是否已經有預設的 Traefik Ingress Controller 因為預設的 Traefik 會占用預設的 80 和 443 端口，所以在安裝 Ingress Controller 之前應該先移除它。\n# 檢查 kube-system 命名空間中是否有 Traefik sudo kubectl get all -n kube-system | grep traefik # 如果有 Traefik 移除它 sudo kubectl delete deployment traefik -n kube-system sudo kubectl delete service traefik -n kube-system 透過 Helm 安裝 Ingress 下載 ingress-nginx。\nsudo helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx sudo helm repo update 加上 ingress-nginx 命名空間，以及指定 Node 加上 Label，讓資源建立在上面。\nsudo kubectl create ns ingress-nginx sudo kubectl label node k8s-node1 ingress=true 安裝 ingress-nginx。\nsudo helm install ingress-nginx ingress-nginx/ingress-nginx \\ --namespace ingress-nginx \\ --set kind=DaemonSet \\ --set nodeSelector.\u0026#34;kubernetes\\.io/os\u0026#34;=linux \\ --set nodeSelector.ingress=true \\ --kubeconfig /etc/rancher/k3s/k3s.yaml 範例 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: test-ingress spec: ingressClassName: \u0026#34;nginx\u0026#34; rules: - host: test.com # Domain 配置 http: paths: - pathType: Prefix backend: service: name: test-svc # 代理到哪個 Service port: number: 80 path: / ","date":"2024-12-31T00:00:00Z","permalink":"https://april23-artist.github.io/p/k8s-install-ingress/","title":"Kubernetes Cluster 安裝 Ingress"},{"content":"前言 將 Jenkins 運行在 Kubernetes 上，可以大大提升 Jenkins 的彈性、擴展性和自動化管理。 Jenkins 可以與 Kubernetes 上的其他服務 (如 Docker、Helm 等) 進行集成，實現更靈活和自動化的 Pipeline 流程。\n步驟 透過 Helm 下載 Jenkins sudo helm repo add jenkinsci https://charts.jenkins.io sudo helm repo update # 查看 Jenkins repo sudo helm search repo jenkinsci 新增 Provisioner 讓建立 Jenkins 時透過 StorageClass 自動產生存取 PVC、PV 在 NFS Node 新增 /home/nfs/rw/jenkins，並且將其加入共享目錄。\n# 加上共享設定 # /home/nfs/rw/jenkins \u0026lt;nfs_server_ip\u0026gt;.0.0/16(rw,sync,no_subtree_check,no_root_squash) sudo nano /etc/exports # 重新加載 exportfs -f sudo systemctl reload nfs-server # \u0026lt;nfs_path\u0026gt;: 共享的目錄 /home/nfs/rw/jenkins sudo helm install \u0026lt;provisioner_name\u0026gt; nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ --version 4.0.18 \\ --namespace nfs \\ --set nfs.server=\u0026lt;nfs_server_ip\u0026gt; \\ --set nfs.path=\u0026lt;nfs_path\u0026gt; \\ --set storageClass.name=\u0026lt;storageClass_name\u0026gt; \\ --kubeconfig /etc/rancher/k3s/k3s.yaml 新增 Service Account 新增 jenkins 命名空間將 Jenkins 相關服務都裝在此命名空間。\nsudo kubectl create ns jenkins 在目錄中新增 jenkins-sa.yaml 並且建立起來。\nsudo kubectl apply -f jenkins-sa.yaml 因為以後會配置 ingress 所以要再加上 resources ingresses 項目。\nrules: - apiGroups: - \u0026#39;*\u0026#39; resources: - ingresses 新增 Values 在目錄中新增 jenkins-values.yaml 並且調整設定。\n# 指定剛才建立的 Provisioner 所提供的 \u0026lt;storageClass_name\u0026gt; storageClass: \u0026lt;storageClass_name\u0026gt; serviceAccount: create: false # Service account name is autogenerated by default name: jenkins annotations: {} 使用 Helm 安裝 Jenkins # 安裝 Jenkins sudo helm install jenkins -n jenkins -f jenkins-values.yaml jenkinsci/jenkins --kubeconfig /etc/rancher/k3s/k3s.yaml # 卸載 Jenkins sudo helm uninstall jenkins -n jenkins --kubeconfig /etc/rancher/k3s/k3s.yaml 將 Service 改為 Type: NodePort 方便測試 # 進入 service 修改 sudo kubectl edit svc jenkins -n jenkins 指定對外的 Port，並且將 Type 改為 NodePort 即可使用 \u0026lt;node_ip\u0026gt;:\u0026lt;port\u0026gt; 連線。\nspec: ports: - nodePort: 30020 type: NodePort 取得 admin 用戶的密碼。\njsonpath=\u0026#34;{.data.jenkins-admin-password}\u0026#34; secret=$(sudo kubectl get secret -n jenkins jenkins -o jsonpath=$jsonpath --kubeconfig /etc/rancher/k3s/k3s.yaml) echo $(echo $secret | base64 --decode) (補充) 使用 Ngrok 將 Jenkins \u0026lt;node_ip\u0026gt;:\u0026lt;port\u0026gt; 公開就可以與其他服務對接 安裝 Ngrok。 進入官網 Ngrok 註冊帳號候登入，即可在 Getting Started \u0026gt; Step \u0026amp; Installation 取得安裝步驟。\nchoco install ngrok ngrok config add-authtoken \u0026lt;auth_token\u0026gt; 執行 Ngrok 將 Jenkins \u0026lt;node_ip\u0026gt;:\u0026lt;port\u0026gt; 公開。\nngrok http http://\u0026lt;node_ip\u0026gt;:\u0026lt;port\u0026gt; 參考 Jenkins Install Jenkins with Helm v3 Ngrok ","date":"2024-12-30T00:00:00Z","permalink":"https://april23-artist.github.io/p/k8s-install-jenkins/","title":"Kubernetes Cluster 安裝 Jenkins"},{"content":"前言 Provisioner 是 Kubernetes 中的一個組件，用於自動化管理持久化存儲資源。它的主要用途包括:\n自動創建存儲資源: 在 K8es 中創建 PersistentVolumeClaim (PVC) 時，Provisioner 會自動創建對應的 PersistentVolume (PV)。 簡化存儲管理：通過使用 Provisioner，無需手動管理存儲資源，減少運維的複雜度。 動態配置存儲：Provisioner 支持動態配置存儲資源，根據應用需求自動調整存儲大小和配置。 多種存儲後端支持：不同的 Provisioner 可以支持不同的存儲後端，如 NFS、Ceph、AWS EBS 等，提供靈活的存儲選擇。 步驟 安裝 Provisioner 自動建立持久化存儲 # 將 Provisioner 安裝在 nfs 命名空間中管理 sudo kubectl create ns nfs # 下載 Provisioner sudo helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/ sudo helm repo update 建立 Provisioner 並設定 StorageClass 的名稱 假設 NFS 服務共享目錄為 /home/nfs/rw/mssql 。\n# 加上共享設定 # /home/nfs/rw/mssql \u0026lt;nfs_server_ip\u0026gt;.0.0/16(rw,sync,no_subtree_check,no_root_squash) sudo nano /etc/exports # 重新加載 exportfs -f sudo systemctl reload nfs-server 建立 Provisioner 並設定 StorageClass 的名稱。\n# \u0026lt;nfs_path\u0026gt;: 共享的目錄 /home/nfs/rw/\u0026lt;file_name\u0026gt; sudo helm install \u0026lt;provisioner_name\u0026gt; nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ --version 4.0.18 \\ --namespace nfs \\ --set nfs.server=\u0026lt;nfs_server_ip\u0026gt; \\ --set nfs.path=\u0026lt;nfs_path\u0026gt; \\ --set storageClass.name=\u0026lt;storageClass_name\u0026gt; \\ --kubeconfig /etc/rancher/k3s/k3s.yaml 在 Statefulset 裡設定使用 \u0026lt;storageClass_name\u0026gt; kind: StatefulSet spec: template: spec: containers: - volumeMounts: - mountPath: /var/opt/mssql volumeClaimTemplates: - metadata: name: {{ .Release.Name }} spec: storageClassName: \u0026lt;storageClass_name\u0026gt; accessModes: - ReadWriteMany resources: requests: storage: 1Gi ","date":"2024-12-30T00:00:00Z","permalink":"https://april23-artist.github.io/p/k8s-provisioner/","title":"Kubernetes Provisioner 自動化管理持久化存儲資源"},{"content":"前言 Helm 可以將 Kubernetes 資源文件 (Deployment、Service、ConfigMap 等) 應用程式打包為 Chart。 可以輕鬆安裝和管理 Chart，並且能夠執行升級、回滾、卸載等操作。Helm 減少了手動編寫和管理 Kubernetes 資源的負擔。\n步驟 安裝 Helm 下載 Helm 後目錄會有 helm-v3.16.3-linux-amd64.tar.gz 文件。\nwget https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz 解壓縮 helm-v3.16.3-linux-amd64.tar.gz 文件。\ntar -zxvf helm-v3.16.3-linux-amd64.tar.gz 進入 linux-amd64 目錄，將 linux-amd64 目錄底下的 helm 複製到 /usr/local/bin/。\ncd linux-amd64/ sudo cp helm /usr/local/bin/ 檢查安裝是否完成。\nhelm version 使用 helm create \u0026lt;chart-name\u0026gt; 新增 chart 新增 chart 會建立一個 \u0026lt;chart-name\u0026gt; 的資料夾。 helm create \u0026lt;chart_name\u0026gt; \u0026lt;chart_name\u0026gt;/ ├── Chart.yaml # Helm Chart 的元數據文件，包含了有關 Chart 的基本信息，例如名稱、版本、描述等。 ├── charts/ # 用來存放其他 Chart 的依賴包。當你在 Chart.yaml 中指定了依賴關係時，這些依賴會被下載並放到這個目錄中。 ├── templates/ # Kubernetes 資源的模板文件。 └── values.yaml # 定義了 Helm Chart 中的默認值，它是 Chart 的配置文件。 常用 helm 指令 helm install \u0026lt;chart_name\u0026gt; # 安裝 helm uninstall \u0026lt;chart_name\u0026gt; # 卸載 helm delete \u0026lt;chart_name\u0026gt; # 刪除 helm upgrade \u0026lt;chart_name\u0026gt; # 升級 helm history \u0026lt;chart_name\u0026gt; # 歷史紀錄 helm rollback \u0026lt;chart_name\u0026gt; \u0026lt;version\u0026gt; # 版本回滾 helm upgrade --install \u0026lt;chart_name\u0026gt; # 安裝或升級 # -n \u0026lt;namespace\u0026gt; 命名空間配置 # --values \u0026lt;values\u0026gt;.yaml 該文件包含 Helm Chart 配置的默認值 # -f \u0026lt;overwrite-values\u0026gt;.yaml 讓你覆蓋默認的配置 helm upgrade --install \u0026lt;chart_name\u0026gt; -n \u0026lt;namespace\u0026gt; --values \u0026lt;values\u0026gt;.yaml -f \u0026lt;overwrite-values\u0026gt;.yaml 參考 Helm ","date":"2024-12-27T00:00:00Z","permalink":"https://april23-artist.github.io/p/k8s-install-helm/","title":"Kubernetes Cluster 安裝 Helm"},{"content":"前言 NFS (Network File System) 是一種共享文件系統，它允許不同的主機或容器之間共享文件或資料夾。 NFS 是一種網路檔案系統協定，可以讓多個容器和 Pod 在不同的節點上訪問同一份數據，這對於需要跨多個 Pod 或節點持久儲存數據的應用非常有用。\n步驟 每個 Node 都需要安裝。\n安裝 NFS 客戶端工具 (nfs-common) # 更新包列表 sudo apt update # 安裝 NFS 客戶端工具 sudo apt install nfs-common 安裝 NFS 伺服器工具 (nfs-kernel-server) sudo apt install nfs-kernel-server 啟動 NFS 伺服器 sudo systemctl start nfs-kernel-server # 檢查 NFS 伺服器狀態 sudo systemctl status nfs-kernel-server # 檢查 NFS 客戶端，使用 showmount 命令查看 NFS 伺服器共享的目錄 showmount -e \u0026lt;nfs_server_ip\u0026gt; 選擇適合共享 NFS 目錄的 Node (適合資料存儲的配置的 Node) 進入 NFS Node，這邊選擇 /home/nfs/rw 作為共享目錄。\ncd /home sudo mkdir nfs cd nfs/ sudo mkdir rw 設置共享目錄。\n# 加上共享設定 # /home/nfs/rw \u0026lt;nfs_server_ip\u0026gt;.0.0/16(rw,sync,no_subtree_check,no_root_squash) sudo nano /etc/exports 重新加載。\nexportfs -f sudo systemctl reload nfs-server (補充) 將 NFS Node 共享目錄掛載到其他 Node 的指定目錄裡 進入其他 Node，選擇要同步共享目錄的資料夾。\nsudo mkdir -p /mnt/nfs/rw sudo mount -t nfs \u0026lt;nfs_server_ip\u0026gt;:/home/nfs/rw /mnt/nfs/rw # 取消掛載 sudo umount /mnt/nfs/rw ","date":"2024-12-27T00:00:00Z","permalink":"https://april23-artist.github.io/p/k8s-install-nfs/","title":"Kubernetes Cluster 安裝 Network File System"},{"content":"前言 Multipass 是輕量化的虛擬機管理工具，選擇搭配 K3s 而不選擇 minikube 是因為 K3s 可以建立多個 Node，非常適合用來學習 Kubernetes 的知識。\n步驟 安裝 Multipass choco install multipass 建立虛擬機 (Node) 建立 3 個 Node ，1 個 Master，2 個 Worker。\nmultipass launch --name k8s-master --cpus 1 --memory 4G --disk 10G multipass launch --name k8s-node1 --cpus 1 --memory 4G --disk 10G multipass launch --name k8s-node2 --cpus 1 --memory 4G --disk 10G 常用的 Multipass 指令。\nmultipass ls # 虛擬機列表 multipass start \u0026lt;node_name\u0026gt; # 啟動虛擬機 multipass stop \u0026lt;node_name\u0026gt; # 關閉虛擬機 multipass shell \u0026lt;node_name\u0026gt; # 進入虛擬機 multipass delete \u0026lt;node_name\u0026gt; # 刪除虛擬機 multipass purge # 清除已刪除虛擬機 # 將虛擬機檔案複製到本機 multipass transfer \u0026lt;node_name\u0026gt;:\u0026lt;file_path\u0026gt; . 在 Master Node 建立 K3s 進入 Master Node。\nmultipass shell k8s-master 在 Master Node 安裝 K3s。\n# 安裝 K3s curl -sfL https://get.k3s.io | sh - # 查看 K3s 配置文件 sudo cat /etc/rancher/k3s/k3s.yaml # 安裝後即可使用 kubectl 指令 sudo kubectl get nodes 將 Worker Node 加入 Master 叢集 輸入 exit 指令離開 Master Node。\n# 取得 Token $TOKEN = multipass exec k8s-master -- sudo cat /var/lib/rancher/k3s/server/node-token # 取得 IP $MASTER_IP = (multipass info k8s-master | Select-String \u0026#34;IPv4\u0026#34; | ForEach-Object { $_ -replace \u0026#39;IPv4:\\s*\u0026#39;, \u0026#39;\u0026#39; }).Trim() # 將 Token、IP 指定給 Worker Node。 For ($f = 1; $f -le 2; $f++) { multipass exec \u0026#34;k8s-node$f\u0026#34; -- bash -c \u0026#34;curl -sfL https://get.k3s.io | K3S_URL=\u0026#39;https://$($MASTER_IP):6443\u0026#39; K3S_TOKEN=\u0026#39;$TOKEN\u0026#39; sh -\u0026#34; } 建立 Master 與 Worker Node 的 SSH 進入 Master Node 產生 SSH 密鑰。\n# 確認 Master Node 是否有 SSH 密鑰 cat ~/.ssh/id_rsa.pub # 若沒有則產生 SSH 密鑰 ssh-keygen -t rsa -b 4096 # 取得 SSH 密鑰 cat ~/.ssh/id_rsa.pub Worker Node 調整 SSH 配置 每個 Worker Node 都要執行。\nmultipass shell k8s-node1 檢查 SSH 服務是否開啟\nsystemctl status ssh 調整 SSH 配置。\n# 進入設定檔，確保以下設置未被註解 (即沒有 #)。 # PubkeyAuthentication yes # AuthorizedKeysFile .ssh/authorized_keys sudo nano /etc/ssh/sshd_config # 重新啟動 SSH 服務 sudo systemctl restart ssh # 將 Master SSH 密鑰寫入授權金鑰 echo \u0026#34;Master SSH 密鑰\u0026#34; \u0026gt;\u0026gt; ~/.ssh/authorized_keys 在 Master Node 執行。\n# 測試 SSH 是否有通 ssh \u0026lt;worker_node_name\u0026gt; 將 Master Node 的 k3s.yaml 配置複製到 Worker Node 進入 Master Node 複製 k3s.yaml 到 Worker Node。\n# SSH 密鑰複製到 root 用戶 sudo cp ~/.ssh/id_rsa /root/.ssh/ sudo cp ~/.ssh/id_rsa.pub /root/.ssh/ # 設定權限 sudo chmod 600 /root/.ssh/id_rsa sudo chmod 644 /root/.ssh/id_rsa.pub # 複製 k3s.yaml 到 Worker Node sudo scp /etc/rancher/k3s/k3s.yaml ubuntu@k8s-node1:/tmp/k3s.yaml 進入 Worker Node ，將 k3s.yaml 的 Server 改為 Master Node 的 IP。\n# 檢查目錄是否存在 ls /etc/rancher/k3s/ # 建立 /etc/rancher/k3s/ 目錄 sudo mkdir -p /etc/rancher/k3s/ # 確保 /tmp/k3s.yaml 文件存在後移動文件 sudo mv /tmp/k3s.yaml /etc/rancher/k3s/k3s.yaml # 修改 Server 變數 # server: https://\u0026lt;master_ip\u0026gt;:6443 sudo nano /etc/rancher/k3s/k3s.yaml 設定 Worker Node 的 KUBECONFIG 進入 Worker Node 添加 KUBECONFIG 環境變數。\n# 添加環境變數 # export KUBECONFIG=/etc/rancher/k3s/k3s.yaml nano ~/.bash_profile # 使變更生效 source ~/.bash_profile (補充) 若 Master Node IP 改變，則調整 Worker Node 的設定重新加入叢集 進入 Worker Node 編輯環境變數文件。\n# 修改 K3S_URL 變數 # K3S_URL=\u0026#39;https://\u0026lt;master_ip\u0026gt;:6443\u0026#39; sudo nano /etc/systemd/system/k3s-agent.service.env # 重新載入和重啟服務 sudo systemctl daemon-reload sudo systemctl restart k3s-agent 參考 Multipass K3s Kubernetes 1 小時入門 ","date":"2024-12-25T00:00:00Z","permalink":"https://april23-artist.github.io/p/multipass-k3s/","title":"Multipass 搭配 K3s 建立 Kubernetes Cluster"},{"content":"前言 想紀錄開發筆記，決定透過 GitHub Actions 自動化部署 Hugo 到 GitHub Pages。\n步驟 Windows 安裝 Hugo 安裝 Chocolatey，使用管理員身分開啟 Windows Terminal。\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;)) 安裝 Hugo，並確認 Hugo 版本。\nchoco install hugo choco install hugo-extended hugo version 建立 GitHub Repository 建立名稱為 \u0026lt;user_name\u0026gt;.github.io 的 Repo 作為 Hugo 的專案。 這裡套用的 hugo theme 為 Stask，直接使用 hugo-theme-stack-stater 範例來修改。 將 hugo-theme-stack-stater 內的檔案放入 \u0026lt;user_name\u0026gt;.github.io。\ngit clone https://github.com/CaiJimmy/hugo-theme-stack-starter.git hugo-theme-stack-starter 因為環境未安裝 Go 在執行 hugo build 時會出錯，所以要稍微調整。 範例專案沒有 theme，需下載 hugo-theme-stack。\ngit clone https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack 將專案內 go.mod, go.sum 刪除。 並調整 config \u0026gt; _default \u0026gt; module.toml。\n- path = \u0026#34;github.com/CaiJimmy/hugo-theme-stack/v3\u0026#34; + path = \u0026#34;hugo-theme-stack\u0026#34; 建置並啟動網站，若成功啟動網站即可將專案 push 到 GitHub。\nhugo build hugo server --disableFastRender 設定 GitHub Pages Repo 新增分支 gh-pages。 Settings \u0026gt; (Code and automation) Pages \u0026gt; (Build and deployment) Branch 設定為分支 gh-pages/(root)。\n設定 Workflow 在分支 main 將範例原本的 .github\\workflows\\deploy.yaml 內容替換，並 push 到 GitHub ，將會自動化部署到 gh-pages 分支。\nname: Deploy Hugo site to GitHub Pages # 設定在 `push` 事件觸發時運行工作流。你可以根據需求修改觸發條件。 on: push: branches: - main # 當推送到 main 分支時觸發 # 定義工作流程的各個步驟 jobs: deploy: runs-on: ubuntu-latest # 使用最新版本的 Ubuntu 運行此工作流 steps: # 1. Checkout repository (將代碼庫檢出到 runner) - name: Checkout code uses: actions/checkout@v3 # 2. 設置 Hugo 環境 - name: Set up Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true # 3. 安裝 Hugo 主題 - name: Install Hugo theme run: | git clone https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack # 4. 建構 Hugo 網站 - name: Build the site working-directory: ./ run: hugo --minify --gc --cleanDestinationDir # 5. 部署到 GitHub Pages (gh-pages 分支) - name: Deploy to GitHub Pages uses: JamesIves/github-pages-deploy-action@v4 with: branch: gh-pages # 部署到 gh-pages 分支 folder: public # Hugo 網站的輸出目錄 clean: true # 部署之前清理已有的文件 參考 Stack 在 Windows 中安裝 Hugo ","date":"2024-12-24T00:00:00Z","permalink":"https://april23-artist.github.io/p/deploy-hugo-to-github-pages/","title":"透過 GitHub Actions 自動化部署 Hugo 到 GitHub Pages"}]